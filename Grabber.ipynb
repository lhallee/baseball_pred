{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in the dataset\n",
      "The column 9th has 0.1% NaN values.\n",
      "There are no NaN values in the dataset\n",
      "There are no NaN values in the dataset\n",
      "The column 9th has 0.1% NaN values.\n",
      "There are no NaN values in the dataset\n",
      "The column 9th has 0.1% NaN values.\n",
      "The column Pitcher has 0.6% NaN values.\n",
      "The column 9th has 0.1% NaN values.\n",
      "The column Pitcher has 0.2% NaN values.\n",
      "The column 8th has 0.1% NaN values.\n",
      "The column 9th has 0.1% NaN values.\n",
      "There are no NaN values in the dataset\n",
      "There are no NaN values in the dataset\n",
      "There are no NaN values in the dataset\n",
      "The column 13 has 99.9% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 99.9% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 50.5% NaN values.\n",
      "The column 99 has 5.1% NaN values.\n",
      "The column 159 has 99.5% NaN values.\n",
      "The column 13 has 100.0% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 81 has 0.3% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 48.8% NaN values.\n",
      "The column 99 has 4.7% NaN values.\n",
      "The column 159 has 99.3% NaN values.\n",
      "The column 13 has 100.0% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 81 has 0.2% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 48.1% NaN values.\n",
      "The column 99 has 4.9% NaN values.\n",
      "The column 159 has 99.5% NaN values.\n",
      "The column 13 has 99.9% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 47.9% NaN values.\n",
      "The column 99 has 4.5% NaN values.\n",
      "The column 159 has 99.3% NaN values.\n",
      "The column 13 has 99.8% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 99.9% NaN values.\n",
      "The column 81 has 0.1% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 48.0% NaN values.\n",
      "The column 99 has 4.8% NaN values.\n",
      "The column 159 has 99.5% NaN values.\n",
      "The column 13 has 99.8% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 46.8% NaN values.\n",
      "The column 99 has 4.9% NaN values.\n",
      "The column 159 has 99.4% NaN values.\n",
      "The column 13 has 100.0% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 99.9% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 47.4% NaN values.\n",
      "The column 99 has 4.5% NaN values.\n",
      "The column 159 has 99.2% NaN values.\n",
      "The column 13 has 100.0% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 51.5% NaN values.\n",
      "The column 99 has 4.9% NaN values.\n",
      "The column 159 has 99.2% NaN values.\n",
      "The column 13 has 99.9% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 85 has 99.9% NaN values.\n",
      "The column 87 has 99.9% NaN values.\n",
      "The column 97 has 48.8% NaN values.\n",
      "The column 99 has 4.9% NaN values.\n",
      "The column 159 has 99.5% NaN values.\n",
      "The column 13 has 99.8% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 81 has 0.1% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 51.4% NaN values.\n",
      "The column 99 has 4.6% NaN values.\n",
      "The column 159 has 99.0% NaN values.\n",
      "The column 13 has 99.8% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 17 has 100.0% NaN values.\n",
      "The column 81 has 0.2% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 53.0% NaN values.\n",
      "The column 99 has 4.2% NaN values.\n",
      "The column 159 has 96.4% NaN values.\n",
      "The column 13 has 99.7% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 81 has 0.2% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 51.0% NaN values.\n",
      "The column 99 has 4.8% NaN values.\n",
      "The column 159 has 99.3% NaN values.\n",
      "The column 13 has 100.0% NaN values.\n",
      "The column 14 has 100.0% NaN values.\n",
      "The column 15 has 100.0% NaN values.\n",
      "The column 81 has 0.4% NaN values.\n",
      "The column 85 has 100.0% NaN values.\n",
      "The column 87 has 100.0% NaN values.\n",
      "The column 97 has 49.3% NaN values.\n",
      "The column 99 has 4.9% NaN values.\n",
      "The column 159 has 99.2% NaN values.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from featureranker.utils import *\n",
    "from featureranker.plots import *\n",
    "from featureranker.rankers import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "xlsx_path = './betting_odds/'\n",
    "txt_path = './game_data/'\n",
    "paths = [path for path in glob.glob(xlsx_path + '*.xlsx')]\n",
    "paths_txt = [path_txt for path_txt in glob.glob(txt_path + '*.txt')]\n",
    "for path in paths:\n",
    "    xlsx_dataframes = pd.read_excel(path)\n",
    "    xlsx_dataframes.columns = xlsx_dataframes.columns.str.replace('[^a-zA-Z0-9]', '')\n",
    "    view_data(xlsx_dataframes)\n",
    "\n",
    "\n",
    "txt_dataframes = []\n",
    "for path_txt in paths_txt:\n",
    "    df = pd.read_csv(path_txt, delimiter = \",\", quotechar='\"', quoting=1, header = None)\n",
    "    # df.columns = df.columns.astype(str).str.replace('[^a-zA-Z0-9]', '')\n",
    "    txt_dataframes.append(df)\n",
    "    view_data(df)\n",
    "# txt_dataframes = txt_dataframes.replace({',': '', '\\\"': ''}, regex=True)\n",
    "\n",
    "# If you want to view the file in Excel, uncomment the following line\n",
    "# os.startfile(xlsx_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date home_team visiting_team home_open visiting_open\n",
      "0      20100404       BOS           NYY      -114          -106\n",
      "1      20100405       WAS           PHI       170          -200\n",
      "2      20100405       NYM           MIA      -115          -105\n",
      "3      20100405       CIN           STL       135          -155\n",
      "4      20100405       PIT           LOS       135          -155\n",
      "...         ...       ...           ...       ...           ...\n",
      "28001  20211027       HOU           ATL      -115          -105\n",
      "28002  20211029       ATL           HOU      -115          -105\n",
      "28003  20211030       ATL           HOU      -115          -105\n",
      "28004  20211031       ATL           HOU      -105          -115\n",
      "28005  20211102       HOU           ATL      -120           100\n",
      "\n",
      "[336072 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def process_dataframes(paths):\n",
    "    xlsx_dataframes = [pd.read_excel(path) for path in paths]\n",
    "    merged_df = pd.concat(xlsx_dataframes)\n",
    "    home_teams_df = merged_df[merged_df['VH'] == 'H']\n",
    "    visiting_teams_df = merged_df[merged_df['VH'] == 'V']\n",
    "\n",
    "    selected_columns_df = pd.DataFrame()\n",
    "    for i in range(len(xlsx_dataframes)):\n",
    "        year = 2010 + i\n",
    "        temp_df = pd.DataFrame({\n",
    "            'date': home_teams_df['Date'].apply(lambda x: str(year) + str(x).zfill(4)).reset_index(drop=True),\n",
    "            'home_team': home_teams_df['Team'].reset_index(drop=True),\n",
    "            'visiting_team': visiting_teams_df['Team'].reset_index(drop=True),\n",
    "            'home_open': home_teams_df['Open'].reset_index(drop=True),\n",
    "            'visiting_open': visiting_teams_df['Open'].reset_index(drop=True)\n",
    "        })\n",
    "        selected_columns_df = pd.concat([selected_columns_df, temp_df])\n",
    "\n",
    "    return selected_columns_df\n",
    "\n",
    "print(process_dataframes(paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date home_team visiting_team home_open visiting_open\n",
      "0   20100404       BOS           NYY      -114          -106\n",
      "1   20100405       WAS           PHI       170          -200\n",
      "2   20100405       NYM           MIA      -115          -105\n",
      "3   20100405       CIN           STL       135          -155\n",
      "4   20100405       PIT           LOS       135          -155\n",
      "5   20100405       MIL           COL      -125           105\n",
      "6   20100405       ATL           CUB      -130           110\n",
      "7   20100405       ARI           SDG      -175           155\n",
      "8   20100405       HOU           SFO       110          -130\n",
      "9   20100405       CWS           CLE      -170           150\n",
      "10  20100405       TEX           TOR      -135           115\n",
      "11  20100405       KAN           DET      -115          -105\n",
      "12  20100405       LAA           MIN      -135           115\n",
      "13  20100405       OAK           SEA       105          -125\n",
      "14  20100406       HOU           SFO      -145           125\n",
      "15  20100406       MIL           COL      -140           120\n"
     ]
    }
   ],
   "source": [
    "print(selected_columns_df.head(16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0    1    2    3   4    5    6   7    8    9    ...  \\\n",
      "0     20100404    0  Sun  NYA  AL    1  BOS  AL    1    7  ...   \n",
      "1     20100405    0  Mon  MIN  AL    1  ANA  AL    1    3  ...   \n",
      "2     20100405    0  Mon  CLE  AL    1  CHA  AL    1    0  ...   \n",
      "3     20100405    0  Mon  DET  AL    1  KCA  AL    1    8  ...   \n",
      "4     20100405    0  Mon  SEA  AL    1  OAK  AL    1    5  ...   \n",
      "...        ...  ...  ...  ...  ..  ...  ...  ..  ...  ...  ...   \n",
      "2425  20101003    0  Sun  CHN  NL  162  HOU  NL  162    0  ...   \n",
      "2426  20101003    0  Sun  ARI  NL  162  LAN  NL  162    1  ...   \n",
      "2427  20101003    0  Sun  WAS  NL  162  NYN  NL  162    2  ...   \n",
      "2428  20101003    0  Sun  SDN  NL  162  SFN  NL  162    0  ...   \n",
      "2429  20101003    0  Sun  COL  NL  162  SLN  NL  162    1  ...   \n",
      "\n",
      "                      151  152       153             154  155       156  \\\n",
      "0               J.D. Drew    9  camem001    Mike Cameron    8  scutm001   \n",
      "1          Howie Kendrick    4  woodb003    Brandon Wood    5  mathj001   \n",
      "2         A.J. Pierzynski    2  teahm001     Mark Teahen    5  ramia003   \n",
      "3     Yuniesky Betancourt    6  kendj001   Jason Kendall    2  getzc001   \n",
      "4              Mark Ellis    4  buckt001     Travis Buck    7  pennc001   \n",
      "...                   ...  ...       ...             ...  ...       ...   \n",
      "2425    Humberto Quintero    2  manzt001  Tommy Manzella    6  figun001   \n",
      "2426          Brad Ausmus    2  johnr008    Reed Johnson    7  lillt001   \n",
      "2427           Josh Thole    2  tejar001    Ruben Tejada    4  pelfm001   \n",
      "2428         Jose Guillen    9  sandp001  Pablo Sandoval    5  sancj002   \n",
      "2429        Matt Pagnozzi    2  ryanb002    Brendan Ryan    6  suppj001   \n",
      "\n",
      "                   157  158  159 160  \n",
      "0        Marco Scutaro    6  NaN   Y  \n",
      "1          Jeff Mathis    2  NaN   Y  \n",
      "2       Alexei Ramirez    6  NaN   Y  \n",
      "3           Chris Getz    4  NaN   Y  \n",
      "4     Cliff Pennington    6  NaN   Y  \n",
      "...                ...  ...  ...  ..  \n",
      "2425   Nelson Figueroa    1  NaN   Y  \n",
      "2426         Ted Lilly    1  NaN   Y  \n",
      "2427      Mike Pelfrey    1  NaN   Y  \n",
      "2428  Jonathan Sanchez    1  NaN   Y  \n",
      "2429       Jeff Suppan    1  NaN   Y  \n",
      "\n",
      "[2430 rows x 161 columns]\n"
     ]
    }
   ],
   "source": [
    "print(txt_dataframes[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date home_team visiting_team    home_pitcher  visiting_pitcher  \\\n",
      "0      20100404       BOS           NYA    Josh Beckett       CC Sabathia   \n",
      "1      20100405       ANA           MIN    Jered Weaver       Scott Baker   \n",
      "2      20100405       CHA           CLE    Mark Buehrle    Jake Westbrook   \n",
      "3      20100405       KCA           DET    Zack Greinke  Justin Verlander   \n",
      "4      20100405       OAK           SEA      Ben Sheets   Felix Hernandez   \n",
      "...         ...       ...           ...             ...               ...   \n",
      "33890  20221005       CLE           KCA    Aaron Civale       Jon Heasley   \n",
      "33891  20221005       HOU           PHI  Framber Valdez     Bailey Falter   \n",
      "33892  20221005       OAK           ANA   Ken Waldichuk     Shohei Ohtani   \n",
      "33893  20221005       SEA           DET  Marco Gonzales   Tyler Alexander   \n",
      "33894  20221005       TEX           NYA      Glenn Otto    Domingo German   \n",
      "\n",
      "       home_score  visiting_score    home_player_1    home_player_2  \\\n",
      "0               9               7  Jacoby Ellsbury   Dustin Pedroia   \n",
      "1               6               3      Erick Aybar      Bobby Abreu   \n",
      "2               6               0      Juan Pierre   Gordon Beckham   \n",
      "3               4               8    David DeJesus  Scott Podsednik   \n",
      "4               3               5      Rajai Davis     Daric Barton   \n",
      "...           ...             ...              ...              ...   \n",
      "33890           9               2      Steven Kwan     Amed Rosario   \n",
      "33891           3               2      Kyle Tucker     Aledmys Diaz   \n",
      "33892           3               2        Tony Kemp      Sean Murphy   \n",
      "33893           5               4  Julio Rodriguez        Ty France   \n",
      "33894           4               2    Marcus Semien   Nathaniel Lowe   \n",
      "\n",
      "         home_player_3  ... visiting_player_2   visiting_player_3  \\\n",
      "0      Victor Martinez  ...      Nick Johnson       Mark Teixeira   \n",
      "1         Torii Hunter  ...    Orlando Hudson           Joe Mauer   \n",
      "2       Carlos Quentin  ...    Grady Sizemore       Shin-Soo Choo   \n",
      "3         Billy Butler  ...      Johnny Damon     Magglio Ordonez   \n",
      "4         Ryan Sweeney  ...     Chone Figgins      Casey Kotchman   \n",
      "...                ...  ...               ...                 ...   \n",
      "33890     Jose Ramirez  ...        Bobby Witt  Vinnie Pasquantino   \n",
      "33891   Yordan Alvarez  ...      Rhys Hoskins       J.T. Realmuto   \n",
      "33892       Seth Brown  ...        Mike Trout       Shohei Ohtani   \n",
      "33893    Mitch Haniger  ...       Javier Baez        Riley Greene   \n",
      "33894    Adolis Garcia  ...     Anthony Rizzo     Oswaldo Cabrera   \n",
      "\n",
      "       visiting_player_4 visiting_player_5  visiting_player_6  \\\n",
      "0         Alex Rodriguez     Robinson Cano       Jorge Posada   \n",
      "1         Justin Morneau   Michael Cuddyer        Jason Kubel   \n",
      "2          Travis Hafner    Jhonny Peralta       Matt LaPorta   \n",
      "3         Miguel Cabrera    Carlos Guillen       Brandon Inge   \n",
      "4         Milton Bradley       Ken Griffey         Jose Lopez   \n",
      "...                  ...               ...                ...   \n",
      "33890    Edward Olivares    Michael Massey        Drew Waters   \n",
      "33891   Nick Castellanos       Jean Segura      Matt Vierling   \n",
      "33892        Taylor Ward        Matt Duffy     David Fletcher   \n",
      "33893  Spencer Torkelson        Eric Haase  Jeimer Candelario   \n",
      "33894     Josh Donaldson     Oswald Peraza       Jose Trevino   \n",
      "\n",
      "        visiting_player_7 visiting_player_8 visiting_player_9 home_open  \\\n",
      "0       Curtis Granderson      Nick Swisher     Brett Gardner       NaN   \n",
      "1            Delmon Young        J.J. Hardy        Nick Punto       NaN   \n",
      "2       Mark Grudzielanek        Lou Marson  Michael Brantley       NaN   \n",
      "3            Gerald Laird    Scott Sizemore      Adam Everett       NaN   \n",
      "4      Franklin Gutierrez       Rob Johnson       Jack Wilson       105   \n",
      "...                   ...               ...               ...       ...   \n",
      "33890          Kyle Isbel        Nate Eaton  Sebastian Rivero       NaN   \n",
      "33891      Dalton Guthrie        Nick Maton    Garrett Stubbs       NaN   \n",
      "33892          Livan Soto          Jo Adell        Max Stassi       NaN   \n",
      "33893     Jonathan Schoop     Brendon Davis     Ryan Kreidler       NaN   \n",
      "33894     Marwin Gonzalez   Kyle Higashioka       Aaron Hicks       NaN   \n",
      "\n",
      "      visiting_open  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4              -125  \n",
      "...             ...  \n",
      "33890           NaN  \n",
      "33891           NaN  \n",
      "33892           NaN  \n",
      "33893           NaN  \n",
      "33894           NaN  \n",
      "\n",
      "[33895 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_data(txt_dataframes, selected_columns_df):\n",
    "    extracted_data_df = pd.DataFrame()\n",
    "    for txt_df in txt_dataframes:\n",
    "        # Extracting required data from the columns based on the provided indices\n",
    "        temp_df = pd.DataFrame({\n",
    "            'date': txt_df.iloc[:, 0].apply(lambda x: str(x)),\n",
    "            'home_team': txt_df.iloc[:, 6],\n",
    "            'visiting_team': txt_df.iloc[:, 3],\n",
    "            'home_pitcher': txt_df.iloc[:, 104],\n",
    "            'visiting_pitcher': txt_df.iloc[:, 102],\n",
    "            'home_score': txt_df.iloc[:, 10],  # Added home score from column 10\n",
    "            'visiting_score': txt_df.iloc[:, 9]  # Added visiting score from column 9\n",
    "        })\n",
    "        # Extracting player names for home and visiting teams\n",
    "        for i in range(9):\n",
    "            temp_df['home_player_'+str(i+1)] = txt_df.iloc[:, 133+3*i].str.split(',').str[0].replace(np.nan, 'Unknown Player')\n",
    "        for i in range(9):\n",
    "            temp_df['visiting_player_'+str(i+1)] = txt_df.iloc[:, 106+3*i].str.split(',').str[0].replace(np.nan, 'Unknown Player')\n",
    "        extracted_data_df = pd.concat([extracted_data_df, temp_df])\n",
    "\n",
    "    # Merging the extracted data with the selected_columns_df on 'date', 'home_team', and 'visiting_team'\n",
    "    final_df = pd.merge(extracted_data_df, selected_columns_df,  how='left', left_on=['date','home_team', 'visiting_team'], right_on = ['date','home_team', 'visiting_team'])\n",
    "\n",
    "    return final_df\n",
    "\n",
    "selected_columns_df = process_dataframes(paths)\n",
    "final_df = extract_data(txt_dataframes, selected_columns_df)\n",
    "print(final_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                           20100405\n",
      "home_team                           OAK\n",
      "visiting_team                       SEA\n",
      "home_pitcher                 Ben Sheets\n",
      "visiting_pitcher        Felix Hernandez\n",
      "home_score                            3\n",
      "visiting_score                        5\n",
      "home_player_1               Rajai Davis\n",
      "home_player_2              Daric Barton\n",
      "home_player_3              Ryan Sweeney\n",
      "home_player_4          Kevin Kouzmanoff\n",
      "home_player_5               Kurt Suzuki\n",
      "home_player_6               Eric Chavez\n",
      "home_player_7                Mark Ellis\n",
      "home_player_8               Travis Buck\n",
      "home_player_9          Cliff Pennington\n",
      "visiting_player_1         Ichiro Suzuki\n",
      "visiting_player_2         Chone Figgins\n",
      "visiting_player_3        Casey Kotchman\n",
      "visiting_player_4        Milton Bradley\n",
      "visiting_player_5           Ken Griffey\n",
      "visiting_player_6            Jose Lopez\n",
      "visiting_player_7    Franklin Gutierrez\n",
      "visiting_player_8           Rob Johnson\n",
      "visiting_player_9           Jack Wilson\n",
      "home_open                           115\n",
      "visiting_open                      -135\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_df.iloc[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./game_and_player_data/final_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-125\n",
      "-135\n",
      "101.54074074074074\n"
     ]
    }
   ],
   "source": [
    "class BettingWallet:\n",
    "    def __init__(self, bet_amount, bet_team, bet_date, home_team, visiting_team):\n",
    "        self.bet_amount = bet_amount\n",
    "        self.bet_team = bet_team  # 1 for visiting team, 0 for home team\n",
    "        self.bet_date = bet_date\n",
    "        self.home_team = home_team\n",
    "        self.visiting_team = visiting_team\n",
    "        self.wallet_balance = 100.0\n",
    "\n",
    "    def calculate_winner(self, row):\n",
    "        if row['home_score'] > row['visiting_score']:\n",
    "            return 0  # home team wins\n",
    "        else:\n",
    "            return 1  # visiting team wins\n",
    "\n",
    "    def calculate_payout(self, row, winner):\n",
    "        print(row['visiting_open'])\n",
    "        if winner == 0:  # home team wins\n",
    "            if row['home_open'] > 0:\n",
    "                return self.bet_amount * (row['home_open'] / 100.0)\n",
    "            else:\n",
    "                return self.bet_amount * (100.0 / abs(row['home_open']))\n",
    "        else:  # visiting team wins\n",
    "            if row['visiting_open'] > 0:\n",
    "                return self.bet_amount * (row['visiting_open'] / 100.0)\n",
    "            else:\n",
    "                return self.bet_amount * (100.0 / abs(row['visiting_open']))\n",
    "\n",
    "    def place_bet(self, df):\n",
    "        for index, row in df.iterrows():\n",
    "            if row['date'] == self.bet_date and row['home_team'] == self.home_team and row['visiting_team'] == self.visiting_team:\n",
    "                winner = self.calculate_winner(row)\n",
    "                if winner == self.bet_team:\n",
    "                    self.wallet_balance += self.calculate_payout(row, winner)\n",
    "                else:\n",
    "                    self.wallet_balance -= self.bet_amount\n",
    "        return self.wallet_balance\n",
    "\n",
    "def place_bet_on_index(df, index, bet_amount, bet_team):\n",
    "    row = df.iloc[index]\n",
    "    betting_wallet = BettingWallet(bet_amount, bet_team, row['date'], row['home_team'], row['visiting_team'])\n",
    "    return betting_wallet.place_bet(df)\n",
    "\n",
    "print(place_bet_on_index(final_df, 5, 1, 1))  # 0 for betting on home team```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5494505494505495"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+100/182\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 6",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vile3\\.cursor-tutor\\projects\\python\\Grabber.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vile3/.cursor-tutor/projects/python/Grabber.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(final_df[\u001b[39m6\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
